{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALWAYS run this code below first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn\n",
    "\n",
    "# Helper functions\n",
    "def is_integer(x):\n",
    "   \n",
    "    try:\n",
    "        return (int(x) == float(x))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ingest_files(directory: str):\n",
    "    \n",
    "    \n",
    "    # If the directory has no trailing slash, add one\n",
    "    if directory[-1] != \"/\":\n",
    "        directory = directory + \"/\"\n",
    "    \n",
    "    all_files = os.listdir(directory)\n",
    "    output = {}\n",
    "    \n",
    "    print(\"Directory \" + directory + \" has \" + str(len(all_files)) + \" files:\")\n",
    "    for i in all_files:\n",
    "        print(\" Reading file \" + i)\n",
    "        output[i] = pd.read_csv(directory + i, dtype = str, skiprows = 1)\n",
    "        \n",
    "        # To remove those lines, find any lines with non-integer IDs\n",
    "        # and remove them\n",
    "        invalid_rows = (output[i].id.apply( lambda x : is_integer(x) == False ))\n",
    "        if invalid_rows.sum() > 0:\n",
    "            print(\" Found \" + str(invalid_rows.sum()) + \" invalid rows which were removed\")\n",
    "            output[i] = output[i][invalid_rows == False]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def clean_perc(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x.strip()[:-1])\n",
    "\n",
    "def clean_date(x):\n",
    "    if pd.isnull(x):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strptime( x, \"%b-%Y\").date()\n",
    "\n",
    "def visualize_columns(data, float_cols, cat_cols, date_cols):\n",
    "    '''\n",
    "    This function visualizes all columns\n",
    "      - Box-and-whisker plots for continuous variables\n",
    "      - Lists of distinct values for categorical columns\n",
    "      - A timeline density for dates\n",
    "    '''\n",
    "    \n",
    "    # FLoat columns\n",
    "    for i in float_cols:\n",
    "        seaborn.boxplot(data[i])\n",
    "\n",
    "        # Print the three highest values\n",
    "        highest_vals = sorted(data[i], reverse=True)[:3]\n",
    "        smallest_val = min(data[i])\n",
    "        plt.text(smallest_val, -0.3, highest_vals[0])\n",
    "        plt.text(smallest_val, -0.2, highest_vals[1])\n",
    "        plt.text(smallest_val, -0.1, highest_vals[2])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    # Categorical columns \n",
    "    for i in cat_cols:\n",
    "        print(i)\n",
    "        print(str(len(set(data[i]))) + \" distinct values\")\n",
    "        print(data[i].value_counts())\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Date columns\n",
    "    for i in date_cols:\n",
    "        data[data[i].isnull() == False][i].apply(lambda x : str(x.year) +\n",
    "                                                \"-\" + str(x.month)).value_counts(ascending = True).plot()\n",
    "        plt.title(i + \" (\" + str(data[i].isnull().sum()) + \" null values)\")\n",
    "        plt.show()\n",
    "\n",
    "# Identify the columns we'll be keeping from the dataset\n",
    "cols_to_pick = [\"id\",\n",
    "                \"loan_amnt\",\n",
    "                \"funded_amnt\",\n",
    "                \"revol_util\",\n",
    "                \"revol_bal\",\n",
    "                \"fico_range_low\",\n",
    "                \"fico_range_high\",\n",
    "                \"pub_rec\",\n",
    "                \"open_acc\",\n",
    "                \"earliest_cr_line\",\n",
    "                \"delinq_2yrs\",\n",
    "                \"dti\",\n",
    "                \"purpose\",\n",
    "                \"issue_d\",\n",
    "                \"annual_inc\",\n",
    "                \"home_ownership\",\n",
    "                \"emp_length\",\n",
    "                \"grade\",\n",
    "                \"term\",\n",
    "                \"int_rate\",\n",
    "                \"installment\",\n",
    "                \"verification_status\",\n",
    "                \"recoveries\",\n",
    "                \"loan_status\",\n",
    "                \"last_pymnt_d\",\n",
    "                \"total_pymnt\"]\n",
    "\n",
    "# Identify the type of each of these column\n",
    "\n",
    "float_cols = [\"loan_amnt\",\n",
    "                \"funded_amnt\",\n",
    "                \"revol_bal\",\n",
    "                \"fico_range_low\",\n",
    "                \"fico_range_high\",\n",
    "                \"pub_rec\",\n",
    "                \"open_acc\",\n",
    "                \"delinq_2yrs\",\n",
    "                \"dti\",\n",
    "                \"annual_inc\",\n",
    "                \"installment\",\n",
    "                \"recoveries\",\n",
    "                \"total_pymnt\"]\n",
    "\n",
    "cat_cols = [\"purpose\",\n",
    "            \"home_ownership\",\n",
    "            \"emp_length\",\n",
    "            \"grade\",\n",
    "            \"term\",\n",
    "            \"verification_status\",\n",
    "            \"loan_status\"]\n",
    "\n",
    "perc_cols = [\"revol_util\",\n",
    "             \"int_rate\"]\n",
    "\n",
    "date_cols = [\"earliest_cr_line\",\n",
    "             \"issue_d\",\n",
    "             \"last_pymnt_d\"]\n",
    "\n",
    "\n",
    "# Ensure that we have types for every column\n",
    "assert set(cols_to_pick) - set(float_cols) - set(cat_cols) - set(perc_cols) - set(date_cols) == set([\"id\"])\n",
    "\n",
    "# Define the names of the four returns we'll be calculating\n",
    "ret_cols = [\"ret_PESS\", \"ret_OPT\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\"]\n",
    "\n",
    "# Some of the columns selected will not be used directly in the model, but will be used to generate other features.\n",
    "# Create variables specifying the features that will be used\n",
    "\n",
    "# All categorical columns other than \"loan_status\" will be used as\n",
    "# discrete features\n",
    "discrete_features = list(set(cat_cols) - set([\"loan_status\"]))\n",
    "\n",
    "# All numeric columns will be used as continuous features\n",
    "continuous_features = list(float_cols + perc_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
