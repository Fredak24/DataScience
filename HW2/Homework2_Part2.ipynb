{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, fbeta_score, classification_report, plot_confusion_matrix\n",
    "\n",
    "def minMaxScaleContinuous(continuousList):\n",
    "    return pd.DataFrame(MinMaxScaler().fit_transform(data[continuousList])\n",
    "                             ,columns=list(data[continuousList].columns)\n",
    "                             ,index = data[continuousList].index)\n",
    "\n",
    "def createDiscreteDummies(discreteList):\n",
    "    return pd.get_dummies(data[discreteList], dummy_na = True, prefix_sep = \"::\", drop_first = False)\n",
    "\n",
    "# save the model to disk\n",
    "def saveModel(filename, model):\n",
    "    joblib.dump(model, filename)\n",
    " \n",
    " \n",
    "# load the model from disk\n",
    "def loadModel(filename):\n",
    "    return joblib.load(filename)\n",
    "\n",
    "'''Function to print model accuracy information'''\n",
    "def printAccuracyInfo(model, X_test, y_test):\n",
    "    print(y_test.value_counts())\n",
    "    # Make predictions against the test set\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    # Show the confusion matrix\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "\n",
    "    # Find the accuracy scores of the predictions against the true classes\n",
    "    print(\"accuracy: %0.3f\" % accuracy_score(y_test, pred))\n",
    "    print(\"recall: %0.3f\" % recall_score(y_test, pred, pos_label=True))\n",
    "    print(\"precision: %0.3f\" % precision_score(y_test, pred, pos_label=True))\n",
    "    print(\"f-measure: %0.3f\" % fbeta_score(y_test, pred, beta=1, pos_label=True))\n",
    "    print(classification_report(y_test,pred))\n",
    "\n",
    "    \n",
    "'''Function to print confusion matrix for a model\n",
    "   You may need to run this to update to scikit-learn version 0.22.1\n",
    "         !pip install -U scikit-learn --user\n",
    "'''\n",
    "def plotConfusionMatrix (negative_label, positive_label, model, X_test, y_test):\n",
    "    titles_options = [(\"Confusion matrix, without normalization\", None,'d'),\n",
    "                      (\"Normalized confusion matrix\", 'true','.3g')]\n",
    "    for title, normalize,val_frmt in titles_options:\n",
    "        disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                                     display_labels=[negative_label,positive_label],\n",
    "                                     cmap=plt.cm.Blues,\n",
    "                                     values_format=val_frmt,\n",
    "                                     normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "        disp.ax_.set_xlabel('Predicted')\n",
    "        disp.ax_.set_ylabel('Actual')\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_roc_curve_1 (model, model_name, X_test, y_test):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from matplotlib import pyplot\n",
    "\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "    # predict probabilities\n",
    "    cf_probs = model.predict_proba(X_test)\n",
    "\n",
    "    # keep probabilities for the positive outcome only\n",
    "    cf_probs = cf_probs[:, 1]\n",
    "\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    cf_auc = roc_auc_score(y_test, cf_probs)\n",
    "\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print(model_name,': ROC AUC=%.3f' % (cf_auc))\n",
    "\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    cf_fpr, cf_tpr, _ = roc_curve(y_test, cf_probs)\n",
    "\n",
    "    # plot the roc curve for the model\n",
    "    pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    pyplot.plot(cf_fpr, cf_tpr, marker='.', label=model_name)\n",
    "\n",
    "    # axis labels\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    \n",
    "%matplotlib inline\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in pickle file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading in pickle file...\")\n",
    "\n",
    "data, discrete_features, continuous_features, ret_cols = pickle.load( open( \"../data/clean_data.pickle\", \"rb\" ) )\n",
    "\n",
    "# Create the outcome\n",
    "data[\"default\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n",
    "# Create a feature for the length of a person's credit history at the\n",
    "# time the loan is issued\n",
    "data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n",
    "continuous_features.append('cr_hist')\n",
    "\n",
    "discrete_features_touse=discrete_features\n",
    "continuous_features_touse = continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population:\n",
      " False    613255\n",
      "True     164011\n",
      "Name: default, dtype: int64\n",
      "Train:\n",
      " False    367757\n",
      "True      98602\n",
      "Name: default, dtype: int64\n",
      "Test:\n",
      " False    245498\n",
      "True      65409\n",
      "Name: default, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create dummies for categorical features and concatenate with continuous features for X or predictor dataframe\n",
    "\n",
    "# Use this line of code if you do not want to scale the continuous features\n",
    "#X_continuous = data[continuous_features_touse]\n",
    "\n",
    "# use this line if you want to scale the continuous features using the MinMaxScaler in the function defined above\n",
    "X_continuous = minMaxScaleContinuous(continuous_features_touse)\n",
    "\n",
    "# create numeric dummy features for the discrete features to be used in modeling\n",
    "X_discrete = createDiscreteDummies(discrete_features_touse)\n",
    "\n",
    "#concatenate the continuous and discrete features into one dataframe\n",
    "X = pd.concat([X_continuous, X_discrete], axis = 1)\n",
    "\n",
    "# this is the target variable \n",
    "target_col = 'default'\n",
    "y=data[target_col]\n",
    "\n",
    "# create a test and train split of the transformed data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.4)\n",
    "\n",
    "print(\"Population:\\n\",y.value_counts())\n",
    "print(\"Train:\\n\", y_train.value_counts())\n",
    "print(\"Test:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will get a model with best fit parameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'penalty': ['l1'], 'C': [0.1], 'solver': ['liblinear']} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "''' These are just example parameter settings. You can change these parameters or add others.\n",
    "    The grid search uses a scoring method of roc_auc. You can change that to another scoring method.\n",
    "'''\n",
    "\n",
    "parameters = {'penalty': [\"l1\"],\n",
    "              'C'      : [0.1],\n",
    "              'solver' : ['liblinear']\n",
    "             }\n",
    "\n",
    "print(\"Parameter grid:\\n{}\".format(parameters),'\\n')\n",
    "\n",
    "grid =  GridSearchCV(LogisticRegression(), parameters, cv=10, return_train_score=True, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# perform grid search cv on training data.  The CV algorithm divides this into training and validation\n",
    "lr_model = grid.fit(X_train, y_train)\n",
    "\n",
    "print('best params ',lr_model.best_params_,'\\n')\n",
    "print('best estimator ',lr_model.best_estimator_,'\\n')\n",
    "print('best validation score ', lr_model.best_score_,'\\n')\n",
    "print('scoring method ', lr_model.scorer_)\n",
    "\n",
    "print(\"Test set accuracy score: {:.7f}\".format(lr_model.score(X_test, y_test)))\n",
    "\n",
    "saveModel('lr_model', lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
