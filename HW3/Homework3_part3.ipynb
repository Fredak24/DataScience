{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general utilities\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, fbeta_score, classification_report, plot_confusion_matrix\n",
    "\n",
    "\n",
    "def minMaxScaleContinuous(continuousList):\n",
    "    return pd.DataFrame(MinMaxScaler().fit_transform(data[continuousList])\n",
    "                             ,columns=list(data[continuousList].columns)\n",
    "                             ,index = data[continuousList].index)\n",
    "\n",
    "def createDiscreteDummies(discreteList):\n",
    "    return pd.get_dummies(data[discreteList], dummy_na = True, prefix_sep = \"::\", drop_first = False)\n",
    "\n",
    "# save the model to disk\n",
    "def saveModel(filename, model):\n",
    "    joblib.dump(model, filename)\n",
    " \n",
    " \n",
    "# load the model from disk\n",
    "def loadModel(filename):\n",
    "    return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in pickle file...\n"
     ]
    }
   ],
   "source": [
    "# This is the code you can use to open your pickle file\n",
    "# Read the data and features from the pickle\n",
    "print(\"Reading in pickle file...\")\n",
    "\n",
    "data, discrete_features, continuous_features, ret_cols = pickle.load( open( \"../Data/clean_data.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the outcome\n",
    "data[\"default\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature for the length of a person's credit history at the\n",
    "# time the loan is issued\n",
    "data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n",
    "continuous_features.append('cr_hist')\n",
    "\n",
    "# define the discrete features you want to use in modeling.\n",
    "# if you want to use all the discrete features, just set discrete_features_touse = discrete_features\n",
    "discrete_features_touse = discrete_features\n",
    "# discrete_features_touse =['purpose', 'term', 'verification_status', 'emp_length', 'home_ownership']\n",
    "\n",
    "# define the continuous features to use in modeling\n",
    "# if you want to use all the continuous features, just set the continuous_features_touse = continuous_features\n",
    "continuous_features_touse = continuous_features\n",
    "# continuous_features_touse = ['loan_amnt', 'funded_amnt','installment','annual_inc','dti','revol_bal','delinq_2yrs','open_acc',\n",
    "#  'pub_rec','fico_range_high','fico_range_low','revol_util','cr_hist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population:\n",
      " False    613255\n",
      "True     164011\n",
      "Name: default, dtype: int64\n",
      "Train:\n",
      " False    367757\n",
      "True      98602\n",
      "Name: default, dtype: int64\n",
      "Test:\n",
      " False    245498\n",
      "True      65409\n",
      "Name: default, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create dummies for categorical features and concatenate with continuous features for X or predictor dataframe\n",
    "\n",
    "# Use this line of code if you do not want to scale the continuous features\n",
    "#X_continuous = data[continuous_features_touse]\n",
    "\n",
    "# use this line if you want to scale the continuous features using the MinMaxScaler in the function defined above\n",
    "X_continuous = minMaxScaleContinuous(continuous_features_touse)\n",
    "\n",
    "# create numeric dummy features for the discrete features to be used in modeling\n",
    "X_discrete = createDiscreteDummies(discrete_features_touse)\n",
    "\n",
    "#concatenate the continuous and discrete features into one dataframe\n",
    "X = pd.concat([X_continuous, X_discrete], axis = 1)\n",
    "\n",
    "# this is the target variable \n",
    "target_col = 'default'\n",
    "y=data[target_col]\n",
    "\n",
    "# create a test and train split of the transformed data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.4)\n",
    "\n",
    "print(\"Population:\\n\",y.value_counts())\n",
    "print(\"Train:\\n\", y_train.value_counts())\n",
    "print(\"Test:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel('lr_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array of grades\n",
    "\n",
    "These are represented as a numeric value 0-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 ... 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "grade = (X_test['grade::B']*1 + X_test['grade::C']*2 + X_test['grade::D']*3 + X_test['grade::E']*4 + X_test['grade::F']*5 + X_test['grade::G']*6 )\n",
    "grade = grade.values\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array of scores (probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99901627e-01 5.80504281e-04 1.86538550e-04 ... 1.00000000e+00\n",
      " 9.97840278e-01 8.87630372e-04]\n"
     ]
    }
   ],
   "source": [
    "prob = model.predict_proba(X_test)\n",
    "prob = prob[:,1]\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank Correlation Using Spearman's Correlation\n",
    "\n",
    "Use the following function to find the rank correlation between the Lending Club grades and the probability of default by your model. \n",
    "\n",
    "You can call the function with those values using your test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def getCorrelation (grades, scores):\n",
    "    coef, p = spearmanr(grades, scores)\n",
    "    print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "    else:\n",
    "        print('Samples are correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.126\n",
      "Samples are correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "getCorrelation(grade, prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
