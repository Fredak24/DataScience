{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Functions for Homeworks 4\n",
    "\n",
    "This notebook contains code to create the regression models needed for homework 4.\n",
    "\n",
    "Please read __ALL__ the comments in the code and the headings. This notebook is NOT intended to be run as a script from top to bottom, although there are some code cells that need to be run first.\n",
    "- The general utility libraries need to be loaded first\n",
    "- Then you need to execute the load data and engineer features code cells\n",
    "- Finally, execute the create X and y from the features code cells\n",
    "\n",
    "You can choose to use utilize the grid search implementations for each algorithm listed below tuning the parameters as defined by the Scikit-Learn documentation.\n",
    "\n",
    "The description box above each algorithm contains a link to sklearn's documentation on that algorithm. Please use that for parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general utilities\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREP AND PREPROCESSING SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the data and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code you can use to open your pickle file\n",
    "# Read the data and features from the pickle\n",
    "data, discrete_features, continuous_features, ret_cols = pickle.load( open( \"Data/clean_data.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature for the length of a person's credit history at the\n",
    "# time the loan is issued\n",
    "data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n",
    "continuous_features.append('cr_hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to use a smaller sample of the data due to time constraints, use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code randomly samples 55% of the rows\n",
    "# change the frac paramter if you want a different % to sample\n",
    "# replace = False insures we won't select the same row twice\n",
    "data=data.sample(frac=.55, replace=False, ).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Calculate PValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPValues (model, X_test, y_test):\n",
    "    params = np.append(model.intercept_,model.coef_)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    newX = pd.DataFrame({\"Constant\":np.ones(len(X_test))}).join(pd.DataFrame(X_test.reset_index(drop=True)))\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    var_b = mse*(np.linalg.pinv(np.dot(newX.T,newX)).diagonal())\n",
    "    sd_b = np.sqrt(var_b)\n",
    "    ts_b = params/ sd_b\n",
    "    p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-len(newX.columns)-1))) for i in ts_b]\n",
    "    sd_b = np.round(sd_b,3)\n",
    "    ts_b = np.round(ts_b,3)\n",
    "    p_values = np.round(p_values,8)\n",
    "    params = np.round(params,4)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"Coeff\"],df[\"SE\"],df[\"t val\"],df[\"Probs\"] = [params,sd_b,ts_b,p_values]\n",
    "    names = ['Intercept']\n",
    "    names.extend(list(X_test))\n",
    "    df.index = names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and y from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def minMaxScaleContinuous(continuousList):\n",
    "    return pd.DataFrame(MinMaxScaler().fit_transform(data[continuousList])\n",
    "                             ,columns=list(data[continuousList].columns)\n",
    "                             ,index = data[continuousList].index)\n",
    "\n",
    "def createDiscreteDummies(discreteList):\n",
    "    return pd.get_dummies(data[discreteList], dummy_na = True, prefix_sep = \"::\", drop_first = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VERY IMPORTANT STEP\n",
    "You need to define which features to use in the modeling. The homework will direct you to either use all the features from the data ingestion and cleaning process or to remove some features because they are defined by LendingClub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discrete features you want to use in modeling.\n",
    "# if you want to use all the discrete features, just set discrete_features_touse = discrete_features\n",
    "discrete_features_touse =['purpose', 'term', 'verification_status', 'emp_length', 'home_ownership']\n",
    "\n",
    "# define the continuous features to use in modeling\n",
    "# if you want to use all the continuous features, just set the continuous_features_touse = continuous_features\n",
    "continuous_features_touse = ['loan_amnt', 'funded_amnt','installment','annual_inc','dti','revol_bal','delinq_2yrs','open_acc',\n",
    " 'pub_rec','fico_range_high','fico_range_low','revol_util','cr_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features_touse=discrete_features\n",
    "continuous_features_touse = continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create dummies for categorical features and concatenate with continuous features for X or predictor dataframe\n",
    "\n",
    "# Use this line of code if you do not want to scale the continuous features\n",
    "#X_continuous = data[continuous_features_touse]\n",
    "\n",
    "# use this line if you want to scale the continuous features using the MinMaxScaler in the function defined above\n",
    "X_continuous = minMaxScaleContinuous(continuous_features_touse)\n",
    "\n",
    "# create numeric dummy features for the discrete features to be used in modeling\n",
    "X_discrete = createDiscreteDummies(discrete_features_touse)\n",
    "\n",
    "#concatenate the continuous and discrete features into one dataframe\n",
    "X = pd.concat([X_continuous, X_discrete], axis = 1)\n",
    "\n",
    "# this is the target variable \n",
    "# 'ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb'\n",
    "\n",
    "# Use this line of code if you do not want to scale the ret_cols\n",
    "y=data['ret_PESS']\n",
    "\n",
    "# use this line if you want to scale the ret_cols using the MinMaxScaler in the function defined above\n",
    "#ret_data = minMaxScaleContinuous(ret_cols)\n",
    "#y=ret_data['ret_PESS']\n",
    "\n",
    "# create a test and train split of the transformed data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important functions to save a model to pickle and load it later\n",
    "Training of these models takes time. It is advisable to save the model as a pickle after you've trained it to your satisfaction so you can use it later for comparison without having to re-train it.\n",
    "\n",
    "The code after the function defintions provides an __example__ of how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save the model to disk\n",
    "def saveModel(filename, model):\n",
    "    joblib.dump(model, filename)\n",
    " \n",
    " \n",
    "# load the model from disk\n",
    "def loadModel(filename):\n",
    "    return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "saveModel('mlr_model', mlr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "mlr_model = loadModel('mlr_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "This is an Multiple Linear Regression.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mlr_model = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: {:.5f}\".format(mlr_model.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.5f}\".format(mlr_model.score(X_test, y_test)))\n",
    "\n",
    "print(\"mlr.coef_:\", mlr_model.coef_)\n",
    "print(\"mlr.intercept_:\", mlr_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "predictions = mlr_model.predict(X_test)\n",
    "score = explained_variance_score(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"score = {:.5f} | MAE = {:.5f} | RMSE = {:.5f} | R2 = {:.5f}\".format(score, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPValues(mlr_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression GridsearchCV\n",
    "This is an example grid search with cross validation using ridge regression. Please note the following:\n",
    "- You can adjust these parameters or add others\n",
    "- The scoring method can be changed\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "''' These are just example parameter settings. You can change these parameters or add others.\n",
    "    The grid search uses a scoring method of R2. You can change that to another scoring method.\n",
    "'''\n",
    "\n",
    "parameters = {'alpha' : [0.001, 0.001, 0.01, 0.1, 1]\n",
    "             }\n",
    "\n",
    "print(\"Parameter grid:\\n{}\".format(parameters),'\\n')\n",
    "\n",
    "grid =  GridSearchCV(Ridge(max_iter=100000), parameters, cv=5, return_train_score=True, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# perform grid search cv on training data.  The CV algorithm divides this into training and validation\n",
    "ridge_model = grid.fit(X_train, y_train)\n",
    "\n",
    "print('best params ',ridge_model.best_params_,'\\n')\n",
    "print('best estimator ',ridge_model.best_estimator_,'\\n')\n",
    "print('best validation score ', ridge_model.best_score_,'\\n')\n",
    "print('scoring method ', ridge_model.scorer_)\n",
    "\n",
    "print(\"Test set accuracy score: {:.7f}\".format(ridge_model.score(X_test, y_test)))\n",
    "\n",
    "saveModel('ridge_model', ridge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression GridsearchCV\n",
    "This is an example grid search with cross validation using lasso regression. Please note the following:\n",
    "- You can adjust these parameters or add others\n",
    "- The scoring method can be changed\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "''' These are just example parameter settings. You can change these parameters or add others.\n",
    "    The grid search uses a scoring method of R2. You can change that to another scoring method.\n",
    "'''\n",
    "\n",
    "parameters = {'alpha' : [0.000000001, 0.00000001, 0.0000001]\n",
    "             }\n",
    "\n",
    "print(\"Parameter grid:\\n{}\".format(parameters),'\\n')\n",
    "\n",
    "grid =  GridSearchCV(Lasso(max_iter=10000), parameters, cv=5, return_train_score=True, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# perform grid search cv on training data.  The CV algorithm divides this into training and validation\n",
    "ls_model = grid.fit(X_train, y_train)\n",
    "\n",
    "print('best params ',ls_model.best_params_,'\\n')\n",
    "print('best estimator ',ls_model.best_estimator_,'\\n')\n",
    "print('best validation score ', ls_model.best_score_,'\\n')\n",
    "print('scoring method ', ls_model.scorer_)\n",
    "\n",
    "print(\"Test set accuracy score: {:.7f}\".format(ls_model.score(X_test, y_test)))\n",
    "\n",
    "saveModel('ls_model', ls_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet Regression GridsearchCV\n",
    "This is an example grid search with cross validation using ElasticNet regression. It is not required that you use this algorithm, but I included it in case you were interested in trying it. It blends L1 and L2 regularization using the l1_ratio parameter.\n",
    "\n",
    "Please note the following:\n",
    "- You can adjust these parameters or add others\n",
    "- The scoring method can be changed\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "''' These are just example parameter settings. You can change these parameters or add others.\n",
    "    The grid search uses a scoring method of R2. You can change that to another scoring method.\n",
    "'''\n",
    "\n",
    "parameters = {'alpha' : [0.000000001, 0.00000001, 0.01],\n",
    "              'l1_ratio': [0.25, 0.5, 0.75]\n",
    "             }\n",
    "\n",
    "print(\"Parameter grid:\\n{}\".format(parameters),'\\n')\n",
    "\n",
    "grid =  GridSearchCV(ElasticNet(max_iter=10000), parameters, cv=5, return_train_score=True, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# perform grid search cv on training data.  The CV algorithm divides this into training and validation\n",
    "en_model = grid.fit(X_train, y_train)\n",
    "\n",
    "print('best params ',en_model.best_params_,'\\n')\n",
    "print('best estimator ',en_model.best_estimator_,'\\n')\n",
    "print('best validation score ', en_model.best_score_,'\\n')\n",
    "print('scoring method ', en_model.scorer_)\n",
    "\n",
    "print(\"Test set accuracy score: {:.7f}\".format(en_model.score(X_test, y_test)))\n",
    "\n",
    "saveModel('en_model', en_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
